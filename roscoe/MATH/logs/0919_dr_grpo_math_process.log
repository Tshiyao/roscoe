[2025-09-23 16:59:56] 开始处理：0919_dr_grpo_math（日志：/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/logs/0919_dr_grpo_math_process.log）
[2025-09-23 16:59:56] 0919_dr_grpo_math：开始清洗
输出文件夹: /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math
读取输入文件: /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/raw/0919_dr_grpo_math//raw.json
写入JSONL文件/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/aime24.jsonl
已生成 /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/aime24.jsonl，包含 30 条记录
写入JSONL文件/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/math500.jsonl
已生成 /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/math500.jsonl，包含 500 条记录
写入JSONL文件/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/amc23.jsonl
已生成 /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/amc23.jsonl，包含 40 条记录
处理完成
[2025-09-23 16:59:56] 0919_dr_grpo_math：开始打分（数据集：amc23）
/root/autodl-tmp/roscoe/ParlAI/parlai/core/opt.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
09/23/2025 17:00:01 - INFO - sentence_transformers.SentenceTransformer -   Use pytorch device_name: cuda:0
09/23/2025 17:00:01 - INFO - sentence_transformers.SentenceTransformer -   Load pretrained SentenceTransformer: all-mpnet-base-v2
Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
aime24.jsonl
['amc23']
Skipping due to --datasets filter: aime24.jsonl
math500.jsonl
['amc23']
Skipping due to --datasets filter: math500.jsonl
Evaluating /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/amc23.jsonl
Batches:   0%|          | 0/49 [00:00<?, ?it/s]Batches:   2%|▏         | 1/49 [00:00<00:19,  2.47it/s]Batches:   6%|▌         | 3/49 [00:00<00:07,  6.51it/s]Batches:  10%|█         | 5/49 [00:00<00:04,  9.45it/s]Batches:  16%|█▋        | 8/49 [00:00<00:03, 13.44it/s]Batches:  22%|██▏       | 11/49 [00:00<00:02, 16.78it/s]Batches:  29%|██▊       | 14/49 [00:01<00:01, 19.98it/s]Batches:  37%|███▋      | 18/49 [00:01<00:01, 24.78it/s]Batches:  47%|████▋     | 23/49 [00:01<00:00, 29.97it/s]Batches:  59%|█████▉    | 29/49 [00:01<00:00, 36.24it/s]Batches:  73%|███████▎  | 36/49 [00:01<00:00, 39.14it/s]Batches:  98%|█████████▊| 48/49 [00:01<00:00, 58.74it/s]Batches: 100%|██████████| 49/49 [00:01<00:00, 29.90it/s]
Batches:   0%|          | 0/4 [00:00<?, ?it/s]Batches:  25%|██▌       | 1/4 [00:00<00:00,  9.19it/s]Batches: 100%|██████████| 4/4 [00:00<00:00, 19.82it/s]
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  5.09it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  7.60it/s]
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches:  50%|█████     | 1/2 [00:00<00:00,  5.29it/s]Batches: 100%|██████████| 2/2 [00:00<00:00,  9.93it/s]
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 56.57it/s]
Batches:   0%|          | 0/2 [00:00<?, ?it/s]Batches: 100%|██████████| 2/2 [00:00<00:00, 60.56it/s]
Scoring chains ... :   0%|          | 0/40 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.
Scoring chains ... :   2%|▎         | 1/40 [00:06<04:04,  6.27s/it]Scoring chains ... :   5%|▌         | 2/40 [01:05<23:43, 37.46s/it]Scoring chains ... :   8%|▊         | 3/40 [01:18<16:03, 26.04s/it]Scoring chains ... :  10%|█         | 4/40 [02:11<22:06, 36.85s/it]Scoring chains ... :  12%|█▎        | 5/40 [03:15<27:14, 46.69s/it]Scoring chains ... :  15%|█▌        | 6/40 [04:03<26:37, 46.97s/it]Scoring chains ... :  18%|█▊        | 7/40 [04:06<18:02, 32.80s/it]Scoring chains ... :  20%|██        | 8/40 [04:17<13:49, 25.93s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors
Scoring chains ... :  22%|██▎       | 9/40 [06:24<29:37, 57.33s/it]Scoring chains ... :  25%|██▌       | 10/40 [07:53<33:36, 67.20s/it]Scoring chains ... :  28%|██▊       | 11/40 [08:07<24:31, 50.75s/it]Scoring chains ... :  30%|███       | 12/40 [08:23<18:51, 40.41s/it]Scoring chains ... :  32%|███▎      | 13/40 [08:42<15:12, 33.79s/it]Scoring chains ... :  35%|███▌      | 14/40 [14:24<55:00, 126.93s/it]Scoring chains ... :  38%|███▊      | 15/40 [14:44<39:25, 94.63s/it] Scoring chains ... :  40%|████      | 16/40 [14:46<26:40, 66.68s/it]Scoring chains ... :  42%|████▎     | 17/40 [14:52<18:34, 48.46s/it]Scoring chains ... :  45%|████▌     | 18/40 [15:00<13:23, 36.52s/it]Scoring chains ... :  48%|████▊     | 19/40 [15:13<10:17, 29.40s/it]Scoring chains ... :  50%|█████     | 20/40 [16:22<13:47, 41.37s/it]Scoring chains ... :  52%|█████▎    | 21/40 [16:37<10:35, 33.45s/it]Scoring chains ... :  55%|█████▌    | 22/40 [19:51<24:27, 81.55s/it]Scoring chains ... :  57%|█████▊    | 23/40 [19:57<16:42, 58.95s/it]Scoring chains ... :  60%|██████    | 24/40 [21:16<17:16, 64.81s/it]Scoring chains ... :  62%|██████▎   | 25/40 [23:21<20:41, 82.77s/it]Scoring chains ... :  65%|██████▌   | 26/40 [23:52<15:43, 67.41s/it]Scoring chains ... :  68%|██████▊   | 27/40 [23:59<10:40, 49.28s/it]Scoring chains ... :  70%|███████   | 28/40 [26:33<16:06, 80.56s/it]Scoring chains ... :  72%|███████▎  | 29/40 [26:50<11:17, 61.60s/it]Scoring chains ... :  75%|███████▌  | 30/40 [27:58<10:33, 63.38s/it]Scoring chains ... :  78%|███████▊  | 31/40 [28:11<07:16, 48.54s/it]Scoring chains ... :  80%|████████  | 32/40 [30:06<09:07, 68.43s/it]Scoring chains ... :  82%|████████▎ | 33/40 [32:03<09:40, 82.89s/it]Scoring chains ... :  85%|████████▌ | 34/40 [32:16<06:11, 61.99s/it]Scoring chains ... :  88%|████████▊ | 35/40 [32:20<03:43, 44.67s/it]Scoring chains ... :  90%|█████████ | 36/40 [32:36<02:24, 36.03s/it]Scoring chains ... :  92%|█████████▎| 37/40 [32:49<01:26, 28.89s/it]Scoring chains ... :  95%|█████████▌| 38/40 [33:48<01:16, 38.17s/it]Scoring chains ... :  98%|█████████▊| 39/40 [34:03<00:31, 31.11s/it]Scoring chains ... : 100%|██████████| 40/40 [35:01<00:00, 39.27s/it]Scoring chains ... : 100%|██████████| 40/40 [35:01<00:00, 52.54s/it]
Scores written to /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/output/0919_dr_grpo_mathall-mpnet-base-v2/scores_amc23.tsv
Max GPU Memory Allocated: 439 MB
[2025-09-23 17:35:20] 0919_dr_grpo_math：打分完成
[2025-09-23 22:36:44] 开始处理：0919_dr_grpo_math（日志：/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/logs/0919_dr_grpo_math_process.log）
[2025-09-23 22:36:44] 0919_dr_grpo_math：开始清洗
输出文件夹: /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math
读取输入文件: /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/raw/0919_dr_grpo_math//raw.json
写入JSONL文件/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/aime24.jsonl
已生成 /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/aime24.jsonl，包含 30 条记录
写入JSONL文件/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/math500.jsonl
已生成 /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/math500.jsonl，包含 500 条记录
写入JSONL文件/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/amc23.jsonl
已生成 /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/amc23.jsonl，包含 40 条记录
处理完成
[2025-09-23 22:36:44] 0919_dr_grpo_math：开始打分（数据集：amc23）
/root/autodl-tmp/roscoe/ParlAI/parlai/core/opt.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Some weights of RobertaModel were not initialized from the model checkpoint at facebook/roscoe-512-roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
aime24.jsonl
['amc23']
Skipping due to --datasets filter: aime24.jsonl
math500.jsonl
['amc23']
Skipping due to --datasets filter: math500.jsonl
Evaluating /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/amc23.jsonl
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:00<00:06,  3.54it/s] 12%|█▏        | 3/25 [00:00<00:03,  6.95it/s] 16%|█▌        | 4/25 [00:00<00:02,  7.16it/s] 24%|██▍       | 6/25 [00:00<00:02,  9.45it/s] 32%|███▏      | 8/25 [00:00<00:01, 10.92it/s] 40%|████      | 10/25 [00:01<00:01, 10.83it/s] 48%|████▊     | 12/25 [00:01<00:01, 11.22it/s] 56%|█████▌    | 14/25 [00:01<00:00, 12.74it/s] 64%|██████▍   | 16/25 [00:01<00:00, 10.96it/s] 72%|███████▏  | 18/25 [00:01<00:00, 11.55it/s] 80%|████████  | 20/25 [00:01<00:00, 12.21it/s] 88%|████████▊ | 22/25 [00:02<00:00, 10.68it/s] 96%|█████████▌| 24/25 [00:02<00:00, 10.90it/s]100%|██████████| 25/25 [00:02<00:00, 10.60it/s]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  7.37it/s]100%|██████████| 2/2 [00:00<00:00,  7.78it/s]100%|██████████| 2/2 [00:00<00:00,  7.71it/s]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 10.57it/s]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 11.03it/s]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 54.24it/s]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.17it/s]
Scoring chains ... :   0%|          | 0/40 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.
Scoring chains ... :   2%|▎         | 1/40 [00:06<04:14,  6.53s/it]Scoring chains ... :   5%|▌         | 2/40 [01:05<23:42, 37.42s/it]Scoring chains ... :   8%|▊         | 3/40 [01:17<15:55, 25.83s/it]Scoring chains ... :   8%|▊         | 3/40 [01:38<20:20, 33.00s/it]
Traceback (most recent call last):
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/roscoe.py", line 262, in <module>
    scores = evaluator.evaluate(score_types=score_types)
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/score.py", line 993, in evaluate
    scores = self.compute_nli_scores(
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/score.py", line 900, in compute_nli_scores
    self.contradiction_step_vs_step(
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/score.py", line 583, in contradiction_step_vs_step
    return self.max_contradiction(chain, chain, batch_size)
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/score.py", line 564, in max_contradiction
    probs.extend(self.contradiction_probability(pr, hyp))
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/score.py", line 547, in contradiction_probability
    output = self.nli_model(**input)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 1079, in forward
    outputs = self.deberta(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 786, in forward
    encoder_outputs = self.encoder(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 659, in forward
    output_states, attn_weights = layer_module(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 438, in forward
    attention_output, att_matrix = self.attention(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 371, in forward
    self_output, att_matrix = self.self(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 251, in forward
    rel_att = self.disentangled_attention_bias(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 343, in disentangled_attention_bias
    p2c_att = torch.bmm(key_layer, pos_query_layer.transpose(-1, -2))
KeyboardInterrupt
[2025-09-23 22:39:03] 开始处理：0919_dr_grpo_math（日志：/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/logs/0919_dr_grpo_math_process.log）
[2025-09-23 22:39:03] 0919_dr_grpo_math：开始清洗
输出文件夹: /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math
读取输入文件: /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/raw/0919_dr_grpo_math//raw.json
写入JSONL文件/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/aime24.jsonl
已生成 /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/aime24.jsonl，包含 30 条记录
写入JSONL文件/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/math500.jsonl
已生成 /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/math500.jsonl，包含 500 条记录
写入JSONL文件/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/amc23.jsonl
已生成 /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/amc23.jsonl，包含 40 条记录
处理完成
[2025-09-23 22:39:03] 0919_dr_grpo_math：开始打分（数据集：amc23）
/root/autodl-tmp/roscoe/ParlAI/parlai/core/opt.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Some weights of RobertaModel were not initialized from the model checkpoint at facebook/roscoe-512-roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
aime24.jsonl
['amc23']
Skipping due to --datasets filter: aime24.jsonl
math500.jsonl
['amc23']
Skipping due to --datasets filter: math500.jsonl
Evaluating /root/autodl-tmp/roscoe/ParlAI/projects/roscoe/MATH/clean/0919_dr_grpo_math/amc23.jsonl
  0%|          | 0/25 [00:00<?, ?it/s]  4%|▍         | 1/25 [00:00<00:08,  2.78it/s]  8%|▊         | 2/25 [00:00<00:04,  4.73it/s] 12%|█▏        | 3/25 [00:00<00:04,  5.42it/s] 16%|█▌        | 4/25 [00:00<00:03,  5.43it/s] 20%|██        | 5/25 [00:00<00:03,  5.80it/s] 24%|██▍       | 6/25 [00:01<00:02,  6.41it/s] 32%|███▏      | 8/25 [00:01<00:02,  6.72it/s] 40%|████      | 10/25 [00:01<00:02,  7.21it/s] 44%|████▍     | 11/25 [00:01<00:01,  7.31it/s] 48%|████▊     | 12/25 [00:01<00:01,  7.76it/s] 56%|█████▌    | 14/25 [00:02<00:01,  9.27it/s] 60%|██████    | 15/25 [00:02<00:01,  8.41it/s] 64%|██████▍   | 16/25 [00:02<00:01,  7.77it/s] 68%|██████▊   | 17/25 [00:02<00:01,  7.80it/s] 76%|███████▌  | 19/25 [00:02<00:00,  9.27it/s] 80%|████████  | 20/25 [00:02<00:00,  9.09it/s] 84%|████████▍ | 21/25 [00:02<00:00,  7.93it/s] 88%|████████▊ | 22/25 [00:03<00:00,  7.52it/s] 92%|█████████▏| 23/25 [00:03<00:00,  7.13it/s] 96%|█████████▌| 24/25 [00:03<00:00,  7.69it/s]100%|██████████| 25/25 [00:03<00:00,  7.40it/s]
  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  5.67it/s]100%|██████████| 2/2 [00:00<00:00,  5.95it/s]100%|██████████| 2/2 [00:00<00:00,  5.90it/s]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  6.94it/s]100%|██████████| 1/1 [00:00<00:00,  6.92it/s]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  9.51it/s]100%|██████████| 1/1 [00:00<00:00,  9.48it/s]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 35.19it/s]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 39.89it/s]
Scoring chains ... :   0%|          | 0/40 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.
Scoring chains ... :   2%|▎         | 1/40 [00:06<04:07,  6.34s/it]Scoring chains ... :   5%|▌         | 2/40 [01:06<24:08, 38.12s/it]Scoring chains ... :   8%|▊         | 3/40 [01:18<16:08, 26.18s/it]Scoring chains ... :  10%|█         | 4/40 [02:12<22:11, 36.98s/it]Scoring chains ... :  12%|█▎        | 5/40 [03:15<27:08, 46.52s/it]Scoring chains ... :  15%|█▌        | 6/40 [04:01<26:18, 46.42s/it]Scoring chains ... :  18%|█▊        | 7/40 [04:05<17:49, 32.41s/it]Scoring chains ... :  20%|██        | 8/40 [04:15<13:33, 25.42s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors
Scoring chains ... :  22%|██▎       | 9/40 [06:22<29:24, 56.92s/it]Scoring chains ... :  25%|██▌       | 10/40 [07:49<33:13, 66.44s/it]Scoring chains ... :  28%|██▊       | 11/40 [08:03<24:17, 50.25s/it]Scoring chains ... :  30%|███       | 12/40 [08:19<18:35, 39.83s/it]Scoring chains ... :  32%|███▎      | 13/40 [08:37<14:57, 33.25s/it]Scoring chains ... :  35%|███▌      | 14/40 [14:14<54:08, 124.92s/it]Scoring chains ... :  38%|███▊      | 15/40 [14:33<38:43, 92.96s/it] Scoring chains ... :  40%|████      | 16/40 [14:34<26:10, 65.45s/it]Scoring chains ... :  42%|████▎     | 17/40 [14:40<18:14, 47.61s/it]Scoring chains ... :  45%|████▌     | 18/40 [14:49<13:08, 35.82s/it]Scoring chains ... :  48%|████▊     | 19/40 [15:01<10:05, 28.85s/it]Scoring chains ... :  50%|█████     | 20/40 [16:09<13:33, 40.66s/it]Scoring chains ... :  52%|█████▎    | 21/40 [16:24<10:22, 32.78s/it]Scoring chains ... :  55%|█████▌    | 22/40 [19:32<23:51, 79.54s/it]Scoring chains ... :  57%|█████▊    | 23/40 [19:39<16:17, 57.48s/it]Scoring chains ... :  60%|██████    | 24/40 [20:56<16:55, 63.46s/it]Scoring chains ... :  62%|██████▎   | 25/40 [22:54<19:57, 79.84s/it]Scoring chains ... :  62%|██████▎   | 25/40 [23:15<13:57, 55.81s/it]
Traceback (most recent call last):
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/roscoe.py", line 262, in <module>
    scores = evaluator.evaluate(score_types=score_types)
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/score.py", line 993, in evaluate
    scores = self.compute_nli_scores(
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/score.py", line 900, in compute_nli_scores
    self.contradiction_step_vs_step(
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/score.py", line 583, in contradiction_step_vs_step
    return self.max_contradiction(chain, chain, batch_size)
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/score.py", line 564, in max_contradiction
    probs.extend(self.contradiction_probability(pr, hyp))
  File "/root/autodl-tmp/roscoe/ParlAI/projects/roscoe/score.py", line 547, in contradiction_probability
    output = self.nli_model(**input)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 1079, in forward
    outputs = self.deberta(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 786, in forward
    encoder_outputs = self.encoder(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 659, in forward
    output_states, attn_weights = layer_module(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 438, in forward
    attention_output, att_matrix = self.attention(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 371, in forward
    self_output, att_matrix = self.self(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 251, in forward
    rel_att = self.disentangled_attention_bias(
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py", line 334, in disentangled_attention_bias
    scale = scaled_size_sqrt(pos_query_layer, scale_factor)
  File "/root/autodl-tmp/.conda/envs/roscoe/lib/python3.10/site-packages/torch/compiler/__init__.py", line 465, in is_exporting
    def is_exporting() -> bool:
KeyboardInterrupt
